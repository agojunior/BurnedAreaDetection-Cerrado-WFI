{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee7b4a00-bd2c-46f5-9608-2ad9d81ec4da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-28T03:56:35.943582Z",
     "iopub.status.busy": "2025-10-28T03:56:35.943245Z",
     "iopub.status.idle": "2025-10-28T04:11:31.424298Z",
     "shell.execute_reply": "2025-10-28T04:11:31.423442Z",
     "shell.execute_reply.started": "2025-10-28T03:56:35.943560Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading grid…\n",
      "Reading labels…\n",
      "Samples after dropping 'pb': 35811\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_22147/3141529247.py:73: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  cent = grid.geometry.centroid\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 235 stacks. First 3: ['20200110CBERS4A_WFI20613220200110.tif.tif', '20200115CBERS4A_WFI20513220200115.tif.tif', '20200120CBERS4A_WFI20413220200120.tif.tif']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|███████████████████████████████████████████████████| 235/235 [10:28<00:00,  2.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assembled N=35811 samples across T=235 dates.\n",
      "Preview:\n",
      "    id 20_labels 21_labels 22_labels  \\\n",
      "0   1        nb        nb        nb   \n",
      "\n",
      "                                                Blue  \\\n",
      "0  [0.05700000002980232, 0.03500000014901161, 0.0...   \n",
      "\n",
      "                                               Green  \\\n",
      "0  [0.054999999701976776, 0.039000000804662704, 0...   \n",
      "\n",
      "                                                 Red  \\\n",
      "0  [0.0430000014603138, 0.027000000700354576, 0.0...   \n",
      "\n",
      "                                                 NIR  \\\n",
      "0  [0.09300000220537186, 0.08399999886751175, 0.0...   \n",
      "\n",
      "                                                 BAI  \\\n",
      "0  [2.2880001068115234, 1.7109999656677246, 2.272...   \n",
      "\n",
      "                                                 EVI  \\\n",
      "0  [0.13600000739097595, 0.14399999380111694, 0.1...   \n",
      "\n",
      "                                                GEMI  \\\n",
      "0  [0.5139999985694885, 0.5509999990463257, 0.460...   \n",
      "\n",
      "                                                NDVI  \\\n",
      "0  [0.25600001215934753, 0.3619999885559082, 0.26...   \n",
      "\n",
      "                                                NDWI  \\\n",
      "0  [0.3709999918937683, 0.5109999775886536, 0.361...   \n",
      "\n",
      "                                               Dates  \n",
      "0  [20200110, 20200115, 20200120, 20200131, 20200...  \n",
      "Saving CSV…\n",
      "✅ Done. Wrote: organized_highres.csv\n"
     ]
    }
   ],
   "source": [
    "# === Build organized_highres.csv from 64 m stacks (assumes consistent band order) ===\n",
    "import os, re, numpy as np, pandas as pd, geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "import rasterio\n",
    "from rasterio.vrt import WarpedVRT\n",
    "from rasterio.enums import Resampling\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ---------------- CONFIG ----------------\n",
    "GPKG_PATH   = \"gpk_spatial_grid.gpkg\"           # your grid file (layer 'gpk_spatial_grid')\n",
    "GPKG_LAYER  = \"gpk_spatial_grid\"\n",
    "LABELS_CSV  = \"Dataset_WFI.csv\"                 # must have id, 20_labels, 21_labels, 22_labels\n",
    "STACKS_DIR  = \"Stacks_RGBNir_BAI_EVI_GEMI_NDVI_NDWI\"  # folder with .tif/.tiff stacks\n",
    "OUT_CSV     = \"organized_highres.csv\"\n",
    "\n",
    "# Canonical column order for output\n",
    "CANON = [\"Blue\",\"Green\",\"Red\",\"NIR\",\"BAI\",\"EVI\",\"GEMI\",\"NDVI\",\"NDWI\"]\n",
    "\n",
    "# Band order inside each TIFF (1-based → 0-based below)\n",
    "# Folder name indicates: [R, G, B, NIR, BAI, EVI, GEMI, NDVI, NDWI]\n",
    "TIFF_ORDER = {\n",
    "    \"Red\":   0,  # band 1\n",
    "    \"Green\": 1,  # band 2\n",
    "    \"Blue\":  2,  # band 3\n",
    "    \"NIR\":   3,  # band 4\n",
    "    \"BAI\":   4,  # band 5\n",
    "    \"EVI\":   5,  # band 6\n",
    "    \"GEMI\":  6,  # band 7\n",
    "    \"NDVI\":  7,  # band 8\n",
    "    \"NDWI\":  8,  # band 9\n",
    "}\n",
    "\n",
    "# Export order\n",
    "EXPORT_IDX = {\n",
    "    \"Blue\":  TIFF_ORDER[\"Blue\"],\n",
    "    \"Green\": TIFF_ORDER[\"Green\"],\n",
    "    \"Red\":   TIFF_ORDER[\"Red\"],\n",
    "    \"NIR\":   TIFF_ORDER[\"NIR\"],\n",
    "    \"BAI\":   TIFF_ORDER[\"BAI\"],\n",
    "    \"EVI\":   TIFF_ORDER[\"EVI\"],\n",
    "    \"GEMI\":  TIFF_ORDER[\"GEMI\"],\n",
    "    \"NDVI\":  TIFF_ORDER[\"NDVI\"],\n",
    "    \"NDWI\":  TIFF_ORDER[\"NDWI\"],\n",
    "}\n",
    "\n",
    "# Extract date from filename (e.g. ...20200131...tif)\n",
    "DATE_RE = re.compile(r\"(\\d{8})\")\n",
    "# ----------------------------------------\n",
    "\n",
    "\n",
    "# --- 1) Load grid and labels ---\n",
    "print(\"Reading grid…\")\n",
    "grid = gpd.read_file(GPKG_PATH, layer=GPKG_LAYER)\n",
    "if grid.crs is None:\n",
    "    grid = grid.set_crs(4326)\n",
    "elif grid.crs.to_epsg() != 4326:\n",
    "    grid = grid.to_crs(4326)\n",
    "\n",
    "grid = grid[[\"id\",\"geometry\"]].copy()\n",
    "\n",
    "print(\"Reading labels…\")\n",
    "labels = pd.read_csv(LABELS_CSV, low_memory=False)\n",
    "keep = [c for c in [\"id\",\"20_labels\",\"21_labels\",\"22_labels\"] if c in labels.columns]\n",
    "labels = labels[keep].drop_duplicates(\"id\")\n",
    "\n",
    "grid = grid.merge(labels, on=\"id\", how=\"left\")\n",
    "grid[\"22_labels\"] = grid[\"22_labels\"].astype(str)\n",
    "grid = grid[grid[\"22_labels\"].isin([\"nb\",\"tb\"])].reset_index(drop=True)\n",
    "print(\"Samples after dropping 'pb':\", len(grid))\n",
    "assert len(grid) > 0, \"No samples retained!\"\n",
    "\n",
    "# Centroids for sampling\n",
    "cent = grid.geometry.centroid\n",
    "pts_xy = np.array([(p.x, p.y) for p in cent], dtype=\"float64\")\n",
    "N = len(grid)\n",
    "\n",
    "# --- 2) Find TIFFs and extract dates ---\n",
    "tif_paths = [os.path.join(STACKS_DIR, f) for f in os.listdir(STACKS_DIR)\n",
    "             if f.lower().endswith((\".tif\",\".tiff\"))]\n",
    "\n",
    "def get_date(fn):\n",
    "    m = DATE_RE.search(os.path.basename(fn))\n",
    "    return m.group(1) if m else None\n",
    "\n",
    "pairs = [(p, get_date(p)) for p in tif_paths]\n",
    "pairs = [(p,d) for (p,d) in pairs if d is not None]\n",
    "pairs.sort(key=lambda x: x[1])\n",
    "assert pairs, \"No valid TIFFs found (date not detected). Check STACKS_DIR or DATE_RE.\"\n",
    "print(f\"Found {len(pairs)} stacks. First 3:\", [os.path.basename(p) for p,_ in pairs[:3]])\n",
    "\n",
    "# --- 3) Sampling loop ---\n",
    "band_series = {b: [] for b in CANON}\n",
    "all_dates = []\n",
    "\n",
    "for tif_path, dstr in tqdm(pairs, desc=\"Sampling\", ncols=100):\n",
    "    all_dates.append(dstr)\n",
    "    with rasterio.open(tif_path) as src:\n",
    "        # ensure in EPSG:4326\n",
    "        if (src.crs is None) or (src.crs.to_epsg() != 4326):\n",
    "            with WarpedVRT(src, crs=\"EPSG:4326\", resampling=Resampling.nearest) as vrt:\n",
    "                vals = np.array(list(vrt.sample(pts_xy)))  # (N,9)\n",
    "        else:\n",
    "            vals = np.array(list(src.sample(pts_xy)))      # (N,9)\n",
    "\n",
    "    # append bands in canonical order\n",
    "    for name in CANON:\n",
    "        band_series[name].append(vals[:, EXPORT_IDX[name]])\n",
    "\n",
    "# --- 4) Convert to per-sample lists ---\n",
    "T = len(all_dates)\n",
    "print(f\"Assembled N={N} samples across T={T} dates.\")\n",
    "\n",
    "per_sample = {}\n",
    "for name in CANON:\n",
    "    arr = np.stack(band_series[name], axis=0).T   # (N,T)\n",
    "    per_sample[name] = [row.tolist() for row in arr]\n",
    "\n",
    "# --- 5) Build output table ---\n",
    "out = pd.DataFrame({\n",
    "    \"id\": grid[\"id\"].values,\n",
    "    \"20_labels\": grid[\"20_labels\"].values if \"20_labels\" in grid.columns else None,\n",
    "    \"21_labels\": grid[\"21_labels\"].values if \"21_labels\" in grid.columns else None,\n",
    "    \"22_labels\": grid[\"22_labels\"].values\n",
    "})\n",
    "for name in CANON:\n",
    "    out[name] = per_sample[name]\n",
    "out[\"Dates\"] = [all_dates] * N\n",
    "\n",
    "print(\"Preview:\\n\", out.head(1))\n",
    "\n",
    "# --- 6) Save CSV ---\n",
    "print(\"Saving CSV…\")\n",
    "out.to_csv(OUT_CSV, index=False)\n",
    "print(\"✅ Done. Wrote:\", OUT_CSV)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983cc3a3-af17-4808-9af4-72c849dd286f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Geospatial)",
   "language": "python",
   "name": "geospatial"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
